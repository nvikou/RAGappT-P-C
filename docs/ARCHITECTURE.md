# ğŸ“ Architecture de l'Application RAG

## Vue d'Ensemble

L'application RAG (Retrieval-Augmented Generation) combine plusieurs technologies pour crÃ©er un systÃ¨me de question-rÃ©ponse intelligent sur le rÃ¨glement technique.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Interface Utilisateur                     â”‚
â”‚                      (Gradio Web UI)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Application RAG (app.py)                   â”‚
â”‚  - Gestion des requÃªtes utilisateur                         â”‚
â”‚  - Streaming des rÃ©ponses                                    â”‚
â”‚  - Formatage des rÃ©sultats                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SystÃ¨me RAG (rag_system.py)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  1. GÃ©nÃ©ration Embeddings (SentenceTransformers)    â”‚   â”‚
â”‚  â”‚     â€¢ multi-qa-mpnet-base-dot-v1                    â”‚   â”‚
â”‚  â”‚     â€¢ 768 dimensions                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  2. Base Vectorielle (ChromaDB)                      â”‚ â”‚
â”‚  â”‚     â€¢ Stockage persistant                            â”‚ â”‚
â”‚  â”‚     â€¢ Recherche par similaritÃ© cosinus               â”‚ â”‚
â”‚  â”‚     â€¢ MÃ©tadonnÃ©es structurÃ©es                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  3. GÃ©nÃ©ration RÃ©ponses (Ollama + LangChain)        â”‚ â”‚
â”‚  â”‚     â€¢ Llama 3.2                                      â”‚ â”‚
â”‚  â”‚     â€¢ TempÃ©rature: 0.1                               â”‚ â”‚
â”‚  â”‚     â€¢ Streaming support                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Module Chunking (chunking.py)                   â”‚
â”‚  - Parsing du rÃ¨glement par articles/points                 â”‚
â”‚  - MÃ©tadonnÃ©es: article_num, title, point_num               â”‚
â”‚  - Format structurÃ© avec IDs uniques                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Workflow de Traitement d'une Question

```
1. Question Utilisateur
   â”‚
   â–¼
2. GÃ©nÃ©ration Embedding Question
   â”‚  (SentenceTransformers)
   â–¼
3. Recherche Vectorielle
   â”‚  (ChromaDB - SimilaritÃ© Cosinus)
   â–¼
4. RÃ©cupÃ©ration Top-K Chunks
   â”‚  (Par dÃ©faut: 5 chunks)
   â–¼
5. Construction du Contexte
   â”‚  (ConcatÃ©nation des chunks)
   â–¼
6. GÃ©nÃ©ration RÃ©ponse
   â”‚  (LLM avec prompt template)
   â–¼
7. Formatage + Sources
   â”‚  (RÃ©ponse + Citations)
   â–¼
8. Affichage Streaming
   â”‚  (Gradio Interface)
   â–¼
9. RÃ©sultat Final
```

## ğŸ“¦ Composants Principaux

### 1. chunking.py
**ResponsabilitÃ©s :**
- TÃ©lÃ©chargement du rÃ¨glement depuis Google Drive
- Parsing structurÃ© par articles et points
- Extraction de mÃ©tadonnÃ©es
- Sauvegarde/chargement des chunks

**MÃ©thode de Chunking :**
```python
RÃ¨glement
  â”œâ”€â”€ Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ X. Titre
  â”‚   â”œâ”€â”€ Point 1 â†’ Chunk X.1
  â”‚   â”œâ”€â”€ Point 2 â†’ Chunk X.2
  â”‚   â””â”€â”€ Point N â†’ Chunk X.N
  â””â”€â”€ ...
```

**Exemple de Chunk :**
```python
{
    'id': '5.3',
    'article_num': '5',
    'article_title': 'Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸',
    'point_num': '3',
    'text': 'Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ...'
}
```

### 2. rag_system.py
**ResponsabilitÃ©s :**
- Initialisation des modÃ¨les (embeddings + LLM)
- Gestion de ChromaDB
- Indexation des chunks
- Recherche sÃ©mantique
- GÃ©nÃ©ration de rÃ©ponses

**Classes principales :**
```python
class RAGSystem:
    - __init__(): Initialisation
    - load_regulation(): Chargement du rÃ¨glement
    - index_chunks(): Indexation ChromaDB
    - retrieve_context(): Recherche vectorielle
    - get_llm_answer(): GÃ©nÃ©ration rÃ©ponse
    - query(): RequÃªte complÃ¨te
    - query_streaming(): Streaming
```

### 3. app.py
**ResponsabilitÃ©s :**
- Interface Gradio
- Gestion des sessions utilisateur
- Streaming des rÃ©ponses
- Configuration serveur

**Classes principales :**
```python
class RAGGradioApp:
    - __init__(): Initialisation RAG
    - rag_interface(): Interface de requÃªte
    - create_interface(): Construction UI
    - launch(): DÃ©marrage serveur
```

### 4. init_database.py
**ResponsabilitÃ©s :**
- TÃ©lÃ©chargement initial du rÃ¨glement
- Parsing et sauvegarde des chunks
- Indexation complÃ¨te dans ChromaDB

### 5. config.py
**ResponsabilitÃ©s :**
- Configuration centralisÃ©e
- Variables d'environnement
- ParamÃ¨tres par dÃ©faut

## ğŸ³ Architecture Docker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     docker-compose.yml                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Container: ollama  â”‚         â”‚ Container: rag-app  â”‚
â”‚                     â”‚         â”‚                     â”‚
â”‚  â€¢ Ollama server    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¢ Python app       â”‚
â”‚  â€¢ Port: 11434      â”‚         â”‚  â€¢ Gradio UI        â”‚
â”‚  â€¢ Llama 3.2        â”‚         â”‚  â€¢ Port: 7860       â”‚
â”‚  â€¢ GPU support      â”‚         â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                â”‚
          â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Volume: ollama_data â”‚         â”‚   Volume: ./data    â”‚
â”‚  â€¢ ModÃ¨les LLM      â”‚         â”‚  â€¢ regulation.txt   â”‚
â”‚  â€¢ Cache            â”‚         â”‚  â€¢ chunks.txt       â”‚
â”‚                     â”‚         â”‚  â€¢ chroma_db/       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ©seau Docker

```
rag-network (bridge)
â”œâ”€â”€ ollama (http://ollama:11434)
â””â”€â”€ rag-app
    â””â”€â”€ AccÃ¨s Ã  ollama via hostname
```

## ğŸ“Š Flux de DonnÃ©es

### Initialisation

```
1. TÃ©lÃ©chargement RÃ¨glement
   â”‚  (Google Drive â†’ data/regulation.txt)
   â–¼
2. Parsing
   â”‚  (regulation.txt â†’ chunks structurÃ©s)
   â–¼
3. GÃ©nÃ©ration Embeddings
   â”‚  (chunks â†’ vecteurs 768D)
   â–¼
4. Indexation ChromaDB
   â”‚  (vecteurs + mÃ©tadonnÃ©es â†’ base vectorielle)
   â–¼
5. SystÃ¨me PrÃªt
```

### RequÃªte Utilisateur

```
1. Input Question
   â”‚  (Interface Gradio)
   â–¼
2. Embedding Question
   â”‚  (Question â†’ vecteur 768D)
   â–¼
3. Recherche SimilaritÃ©
   â”‚  (Vecteur question vs ChromaDB)
   â”‚  â€¢ Calcul cosinus similarity
   â”‚  â€¢ Top-K rÃ©sultats (default: 5)
   â–¼
4. Construction Prompt
   â”‚  â€¢ Template + Contexte + Question
   â”‚  â€¢ Limite: 4000 tokens
   â–¼
5. GÃ©nÃ©ration LLM
   â”‚  (Ollama/Llama 3.2)
   â”‚  â€¢ Streaming token par token
   â–¼
6. Formatage RÃ©ponse
   â”‚  â€¢ RÃ©ponse gÃ©nÃ©rÃ©e
   â”‚  â€¢ Sources (3 premiÃ¨res)
   â”‚  â€¢ MÃ©tadonnÃ©es (articles/points)
   â–¼
7. Display
   â”‚  (Gradio Markdown)
```

## ğŸ” SÃ©curitÃ© et Isolation

- âœ… **Docker Network Isolation** : Les conteneurs communiquent via rÃ©seau privÃ©
- âœ… **Volume Persistence** : DonnÃ©es persistantes en dehors des conteneurs
- âœ… **Port Mapping** : Seuls les ports nÃ©cessaires exposÃ©s
- âœ… **LLM Local** : Aucune donnÃ©e envoyÃ©e Ã  des APIs externes

## ğŸ“ˆ ScalabilitÃ©

### Points d'Extension

1. **ModÃ¨les d'Embeddings**
   - Changer dans config.py
   - Supports : sentence-transformers, OpenAI, etc.

2. **Base Vectorielle**
   - ChromaDB (actuel)
   - Alternatives : Pinecone, Weaviate, FAISS

3. **LLM**
   - Ollama (actuel)
   - Alternatives : OpenAI API, HuggingFace, etc.

4. **Interface**
   - Gradio (actuel)
   - Alternatives : Streamlit, FastAPI, etc.

### Performance

- **Embeddings** : ~100ms par requÃªte
- **Recherche ChromaDB** : ~50ms pour 1000+ chunks
- **LLM GÃ©nÃ©ration** : 2-5s selon la longueur
- **Total** : ~3-6s par requÃªte complÃ¨te

## ğŸ§ª Tests

Voir [test_rag.py](test_rag.py) :
- Tests unitaires pour chunking
- Tests d'embeddings
- Tests d'intÃ©gration

## ğŸ“ Logs et Monitoring

```
docker-compose logs -f
â”œâ”€â”€ ollama : Logs du serveur Ollama
â””â”€â”€ rag-app : Logs de l'application
    â”œâ”€â”€ RequÃªtes utilisateur
    â”œâ”€â”€ Temps de rÃ©ponse
    â””â”€â”€ Erreurs
```

## ğŸ”§ Maintenance

### Mise Ã  jour du RÃ¨glement

```bash
# 1. Nouveau fichier
cp nouveau_reglement.txt data/regulation.txt

# 2. RÃ©indexation
python init_database.py
```

### Mise Ã  jour du ModÃ¨le LLM

```bash
docker-compose exec ollama ollama pull llama3.2:latest
docker-compose restart rag-app
```

---

**Architecture conÃ§ue pour la performance, la maintenabilitÃ© et l'extensibilitÃ©.**
